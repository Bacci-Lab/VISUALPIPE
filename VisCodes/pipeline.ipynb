{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUAL PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import sys\n",
    "from PyQt5 import QtWidgets\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import pickle\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "from Running_computation import compute_speed\n",
    "from Ca_imaging import CaImagingDataManager\n",
    "from face_camera import FaceCamDataManager\n",
    "from visual_stim import VisualStim\n",
    "import General_functions\n",
    "from visualization_GUI import VisualizationGUI\n",
    "import Photodiode\n",
    "from inputUI import InputWindow\n",
    "import red_cell_function\n",
    "import utils.file as file\n",
    "from trial import Trial\n",
    "import behavioral_states\n",
    "import spontaneous as spont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "base_path = \"C:/Users/mai-an.nguyen/Documents/16-00-59\"\n",
    "red_image_path = 'C:/Users/mai-an.nguyen/Documents/16-00-59/SingleImage-red/red.tif'\n",
    "compile_dir = ''\n",
    "\n",
    "# analysis settings\n",
    "neuropil_impact_factor = 0.7\n",
    "F0_method = 'sliding' #sliding or hamming\n",
    "neuron_type = 'Other' #PYR or Other\n",
    "starting_delay_2p = 0.100\n",
    "num_samples = 1000\n",
    "\n",
    "speed_threshold = 0.5\n",
    "facemotion_threshold = 2\n",
    "pupil_threshold = 2\n",
    "pupil_threshold_type = 'std' #std or quantile\n",
    "\n",
    "min_run_window = 3.5\n",
    "min_as_window = 2.5\n",
    "min_rest_window = 1.5\n",
    "\n",
    "speed_filter_kernel = 10\n",
    "motion_filter_kernel = 10\n",
    "pupil_filter_kernel = 10\n",
    "dFoF_filter_kernel = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No excel file for mouse metadata found : C:/Users/mai-an.nguyen/Documents/16-00-59\\demo-Mouse.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Get metadata\n",
    "unique_id, global_protocol, experimenter, subject_id = file.get_metadata(base_path)\n",
    "subject_id_anibio = file.get_mouse_id(base_path, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_image_grayscale.png already exist.\n",
      "Original number of neurons : 35\n"
     ]
    }
   ],
   "source": [
    "# Load Ca-Imaging data\n",
    "ca_img_dm = CaImagingDataManager(base_path, neuropil_impact_factor, F0_method, neuron_type, starting_delay_2p)\n",
    "ca_img_dm.save_mean_image(base_path)\n",
    "ca_img_dm.save_max_proj_image(base_path)\n",
    "detected_roi = ca_img_dm._list_ROIs_idx\n",
    "print('Original number of neurons :', len(detected_roi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/mai-an.nguyen/Documents/16-00-59\\FaceIt\\FaceIt.npz doesn't exist.\n"
     ]
    }
   ],
   "source": [
    "# Load Camera data\n",
    "timestamp_start = Photodiode.get_timestamp_start(base_path)\n",
    "face_cam_dm = FaceCamDataManager(base_path, timestamp_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute speed\n",
    "speed, speed_time_stamps = compute_speed(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration of the recording: 2622.907376334 s\n"
     ]
    }
   ],
   "source": [
    "# Resample facemotion, pupil and speed traces\n",
    "if not face_cam_dm.no_face_data :\n",
    "    last_F_index = np.argmin(np.abs(ca_img_dm.time_stamps - face_cam_dm.time_stamps[-1]))\n",
    "    ca_img_dm.cut_frames(last_index=last_F_index) #update metrics with new frames length\n",
    "new_time_stamps = ca_img_dm.time_stamps\n",
    "total_duration = ca_img_dm.time_stamps[-1] - ca_img_dm.time_stamps[0]\n",
    "print(f\"Total duration of the recording: {total_duration} s\")\n",
    "\n",
    "#sub sampling and filtering speed\n",
    "speed = General_functions.resample_signal(speed, \n",
    "                                          t_sample=speed_time_stamps, \n",
    "                                          new_freq=ca_img_dm.fs,\n",
    "                                          interp_time=new_time_stamps,\n",
    "                                          post_smoothing=2./50.)\n",
    "\n",
    "if not face_cam_dm.no_face_data :\n",
    "    pupil = General_functions.resample_signal(face_cam_dm.pupil, \n",
    "                                              t_sample=face_cam_dm.time_stamps, \n",
    "                                              new_freq=ca_img_dm.fs, \n",
    "                                              interp_time=new_time_stamps)\n",
    "    facemotion = General_functions.resample_signal(face_cam_dm.facemotion, \n",
    "                                                   t_sample=face_cam_dm.time_stamps,\n",
    "                                                   new_freq=ca_img_dm.fs, \n",
    "                                                   interp_time=new_time_stamps)\n",
    "\n",
    "    # Normalize\n",
    "    pupil = General_functions.scale_trace(pupil)\n",
    "    facemotion = General_functions.scale_trace(facemotion)\n",
    "else :\n",
    "    facemotion, pupil = [np.nan] * len(new_time_stamps), [np.nan] * len(new_time_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Photodiode data\n",
    "NIdaq, acq_freq = Photodiode.load_and_data_extraction(base_path)\n",
    "Psignal_time, Psignal = General_functions.resample_signal(NIdaq['analog'][0],\n",
    "                                                          original_freq=acq_freq,\n",
    "                                                          new_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name  duration\n",
      "id                                    \n",
      "0                moving-dots       3.0\n",
      "1                random-dots       3.0\n",
      "2               static-patch       1.0\n",
      "3               looming-stim       5.0\n",
      "4   Natural-Images-4-repeats       2.0\n",
      "5                 grey-20min    1200.0\n",
      "6          drifting-gratings       3.0\n"
     ]
    }
   ],
   "source": [
    "# Load Stimuli data\n",
    "visual_stim = VisualStim(base_path)\n",
    "protocol_df = visual_stim.protocol_df\n",
    "protocol_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create saving folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/mai-an.nguyen/Documents/16-00-59\\2024_09_03_16-00-59_output_14\n",
      "C:/Users/mai-an.nguyen/Documents/16-00-59\\2024_09_03_16-00-59_output_14\\2024_09_03_16-00-59_figures\n"
     ]
    }
   ],
   "source": [
    "# Create saving folder\n",
    "save_dir, save_fig_dir, id_version = file.create_output_folder(base_path, unique_id)\n",
    "\n",
    "\"\"\" id_version = '1'\n",
    "save_dir = os.path.join(base_path, \"_\".join([unique_id, 'output', id_version]))\n",
    "save_fig_dir = os.path.join(save_dir, \"_\".join([unique_id, 'figures'])) \"\"\"\n",
    "\n",
    "print(save_dir)\n",
    "print(save_fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcium Imaging Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing bad neuropil neurons, nb of neurons : 31\n"
     ]
    }
   ],
   "source": [
    "# Detect ROIs with bad neuropils\n",
    "ca_img_dm.detect_bad_neuropils()\n",
    "kept2p_ROI = ca_img_dm._list_ROIs_idx\n",
    "print('After removing bad neuropil neurons, nb of neurons :', len(kept2p_ROI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining neurons after alpha calculation : 31\n"
     ]
    }
   ],
   "source": [
    "# Compute Fluorescence \n",
    "ca_img_dm.compute_F()\n",
    "kept_ROI_alpha = ca_img_dm._list_ROIs_idx\n",
    "print('Number of remaining neurons after alpha calculation :', len(kept_ROI_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining neurons after F0 calculation  : 30\n"
     ]
    }
   ],
   "source": [
    "# Calculation of F0\n",
    "ca_img_dm.compute_F0(percentile=10, win=60)\n",
    "kept_ROI_F0 = ca_img_dm._list_ROIs_idx\n",
    "print('Number of remaining neurons after F0 calculation  :', len(kept_ROI_F0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of dF over F0\n",
    "ca_img_dm.compute_dFoF0()\n",
    "computed_F_norm = ca_img_dm.normalize_time_series(\"dFoF0\", lower=0, upper=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot calcium imaging traces\n",
    "ca_img_dm.plot('f0', sigma=0, mean=True, save_dir=save_fig_dir, legend=True)\n",
    "ca_img_dm.plot('fluorescence', sigma=10, save_dir=save_fig_dir, legend=True)\n",
    "ca_img_dm.plot('dFoF0', sigma=10, save_dir=save_fig_dir, legend=True)\n",
    "ca_img_dm.plot_raster('fluorescence', sigma=10, save_dir=save_fig_dir)\n",
    "ca_img_dm.plot_raster('dFoF0', sigma=10, save_dir=save_fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_corr_list = [spearmanr(speed, ROI)[0] for ROI in ca_img_dm.dFoF0]\n",
    "facemotion_corr_list = [spearmanr(facemotion, ROI)[0] for ROI in ca_img_dm.dFoF0]\n",
    "pupil_corr_list = [spearmanr(pupil, ROI)[0] for ROI in ca_img_dm.dFoF0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align times series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set real stimuli onset with photodiode\n",
    "visual_stim.realign_from_photodiode(Psignal_time, Psignal)\n",
    "Psignal = General_functions.scale_trace(Psignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stimuli start times and durations with calcium imaging data as a the basis\n",
    "stim_time_end = list(visual_stim.real_time_onset + visual_stim.duration)\n",
    "stim_time_period = [visual_stim.real_time_onset, stim_time_end]\n",
    "\n",
    "F_Time_start_realigned, F_stim_init_indexes  = Photodiode.Find_F_stim_index(visual_stim.real_time_onset, ca_img_dm.time_stamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute behavioral states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate index boundaries of dark stimulus\n",
    "idx_dark = np.argwhere(np.array(visual_stim.analyze_pupil) == 0)\n",
    "idx_lim_dark, _ = visual_stim.get_protocol_onset_index(idx_dark, F_stim_init_indexes, ca_img_dm.fs)\n",
    "idx_lim_dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_states_window = {'run' : round(min_run_window * ca_img_dm.fs), \n",
    "                     'AS' : round(min_as_window * ca_img_dm.fs), \n",
    "                     'rest' : round(min_rest_window * ca_img_dm.fs)}\n",
    "\n",
    "if not face_cam_dm.no_face_data :\n",
    "    # Facemotion threshold\n",
    "    real_time_states_facemotion, states_window_facemotion =\\\n",
    "        behavioral_states.split_stages(speed, facemotion, speed_threshold, facemotion_threshold, \n",
    "                                       ca_img_dm.time_stamps, min_states_window, ca_img_dm.fs, \n",
    "                                       'std', speed_filter_kernel, motion_filter_kernel)\n",
    "\n",
    "    behavioral_states.stage_plot(speed, facemotion, pupil, ca_img_dm.dFoF0, \n",
    "                                 ca_img_dm.time_stamps, real_time_states_facemotion, states_window_facemotion, \n",
    "                                 save_fig_dir, speed_threshold, facemotion_threshold,'std', 'facemotion', \n",
    "                                 speed_filter_kernel, motion_filter_kernel, pupil_filter_kernel, dFoF_filter_kernel,\n",
    "                                 svg=False)\n",
    "\n",
    "    run_ratio_facemotion, as_ratio_facemotion, rest_ratio_facemotion =\\\n",
    "        behavioral_states.time_pie(real_time_states_facemotion, total_duration, \n",
    "                                   save_fig_dir,figname=\"states_duration_pie_facemotion\")\n",
    "\n",
    "    # Pupil threshold\n",
    "    if len(idx_lim_dark) == 0 :\n",
    "        real_time_states_pupil, states_window_pupil =\\\n",
    "            behavioral_states.split_stages(speed, pupil, speed_threshold, pupil_threshold, \n",
    "                                        ca_img_dm.time_stamps, min_states_window, ca_img_dm.fs, \n",
    "                                        pupil_threshold_type, speed_filter_kernel, pupil_filter_kernel)\n",
    "\n",
    "        behavioral_states.stage_plot(speed, facemotion, pupil, ca_img_dm.dFoF0, \n",
    "                                    ca_img_dm.time_stamps, real_time_states_pupil, states_window_pupil, \n",
    "                                    save_fig_dir, speed_threshold, pupil_threshold, pupil_threshold_type, 'pupil', \n",
    "                                    speed_filter_kernel, motion_filter_kernel,  pupil_filter_kernel, dFoF_filter_kernel, \n",
    "                                    svg=False)\n",
    "    else :\n",
    "        real_time_states_pupil, states_window_pupil =\\\n",
    "            behavioral_states.split_stages_mixed(speed, pupil, facemotion, idx_lim_dark,\n",
    "                                                 speed_threshold, pupil_threshold, facemotion_threshold,\n",
    "                                                 ca_img_dm.time_stamps, min_states_window, ca_img_dm.fs, \n",
    "                                                 pupil_threshold_type, 'std',\n",
    "                                                 speed_filter_kernel, pupil_filter_kernel, motion_filter_kernel)\n",
    "        \n",
    "        behavioral_states.stage_plot_mixed(speed, facemotion, pupil, ca_img_dm.dFoF0, \n",
    "                                            ca_img_dm.time_stamps, real_time_states_pupil, states_window_pupil, idx_lim_dark, ca_img_dm.fs,\n",
    "                                            save_fig_dir, speed_threshold, pupil_threshold, facemotion_threshold, \n",
    "                                            pupil_threshold_type, 'std', \n",
    "                                            speed_filter_kernel, motion_filter_kernel,  pupil_filter_kernel, dFoF_filter_kernel, \n",
    "                                            svg=False)\n",
    "    \n",
    "    run_ratio_pupil, as_ratio_pupil, rest_ratio_pupil =\\\n",
    "        behavioral_states.time_pie(real_time_states_pupil, total_duration, \n",
    "                                   save_fig_dir, figname=\"states_duration_pie_pupil\")\n",
    "else :\n",
    "    real_time_states, states_window =\\\n",
    "        behavioral_states.split_stages_locomotion(speed, speed_threshold, \n",
    "                                                  ca_img_dm.time_stamps, min_states_window, ca_img_dm.fs, speed_filter_kernel)\n",
    "\n",
    "    behavioral_states.stage_plot_locomotion(speed, ca_img_dm.dFoF0, \n",
    "                                            ca_img_dm.time_stamps, real_time_states, states_window, \n",
    "                                            save_fig_dir, speed_threshold, speed_filter_kernel, \n",
    "                                            dFoF_filter_kernel,\n",
    "                                            svg=False)\n",
    "\n",
    "    run_ratio, rest_ratio =\\\n",
    "        behavioral_states.time_pie_locomotion(real_time_states, total_duration, \n",
    "                                   save_fig_dir,figname=\"states_duration_pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial-averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Trial instance\n",
    "trials = Trial(ca_img_dm, visual_stim, F_stim_init_indexes, attr='dFoF0', dt_pre_stim=1, dt_post_stim=1, auc_thr=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute responsive neurons\n",
    "trials.find_responsive_rois(save_dir, folder_prefix=\"_\".join([unique_id, id_version]))\n",
    "\n",
    "# Save results in file\n",
    "filename = \"_\".join([unique_id, id_version, 'protocol_validity_2'])\n",
    "trials.save_protocol_validity(save_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute contextual modulation index\n",
    "if \"center-surround-cross\" in visual_stim.protocol_names :\n",
    "    cmi = trials.compute_cmi()\n",
    "    trials.plot_cmi_hist(cmi, save_fig_dir)\n",
    "    trials.plot_iso_vs_cross(save_fig_dir)\n",
    "    surround_sup_cross, surround_sup_iso = trials.compute_surround_sup()\n",
    "else :\n",
    "    cmi = None\n",
    "    surround_sup_cross, surround_sup_iso = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the trial zscores not based on the averaged baseline but the baseline of the trace (used for plotting)\n",
    "trial_zscores, pre_trial_zscores, post_trial_zscores = trials.compute_trial_zscores('dFoF0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trials related figures\n",
    "for i in range(len(protocol_df)):    \n",
    "    if visual_stim.stim_cat[i] :\n",
    "\n",
    "        #plot trial-averaged z-score raster sorted\n",
    "        trials.trial_average_rasterplot(i, savepath=save_fig_dir) \n",
    "\n",
    "        #plot trial-averaged z-score raster not sorted\n",
    "        trials.trial_average_rasterplot(i, savepath=save_fig_dir, sort=False)\n",
    "\n",
    "        #plot trial-averaged z-score raster sorted and normalized\n",
    "        trials.trial_average_rasterplot(i, savepath=save_fig_dir, normalize=True)\n",
    "        \n",
    "        #plot trials z-score raster with paired baseline\n",
    "        trials.trial_rasterplot(trial_zscores, pre_trial_zscores, post_trial_zscores, i, 'dFoF0', savepath=save_fig_dir)\n",
    "        \n",
    "        #plot trials z-score raster with averaged baseline\n",
    "        #trials.trial_rasterplot(trials.trial_zscores, trials.pre_trial_zscores, trials.post_trial_zscores, i, trials.ca_attr, savepath=save_fig_dir)\n",
    "        \n",
    "        for k in range(len(ca_img_dm._list_ROIs_idx)):\n",
    "            #plot trial-averaged z-score traces\n",
    "            trials.plot_stim_response(i, k, save_dir, folder_prefix=\"_\".join([unique_id, id_version]))\n",
    "\n",
    "            #plot trial-averaged normalized with baseline traces\n",
    "            trials.plot_norm_trials(i, k, save_dir, folder_prefix=\"_\".join([unique_id, id_version]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Behavioral states of mouse during trials\n",
    "\n",
    "if not face_cam_dm.no_face_data :\n",
    "    real_time_states_sorted = behavioral_states.sort_dict_el(real_time_states_pupil)\n",
    "else :\n",
    "    real_time_states_sorted = behavioral_states.sort_dict_el(real_time_states)\n",
    "\n",
    "# Sort trials by arousal states (output in trials.npy)\n",
    "trials.sort_trials_by_states(F_Time_start_realigned, real_time_states_sorted)\n",
    "\n",
    "# Compute averaged traces by arousal states\n",
    "trials.compute_avg_by_states()\n",
    "\n",
    "for i in range(len(protocol_df)):    \n",
    "    if visual_stim.stim_cat[i] :\n",
    "        \n",
    "        #plot trials with behavioral states\n",
    "        trials.plot_stim_occurence(i, trial_zscores, pre_trial_zscores, real_time_states_sorted, F_Time_start_realigned, save_dir, folder_prefix=\"_\".join([unique_id, id_version]))\n",
    "        \n",
    "        for k in range(len(ca_img_dm._list_ROIs_idx)):\n",
    "            #plot trial-averaged traces per arousal states\n",
    "            trials.plot_trials_per_states(i, k, save_dir, folder_prefix=\"_\".join([unique_id, id_version]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Method : Bootstrapping Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method : Bootstrapping\n",
    "protocol_validity = []\n",
    "for protocol in range(len(protocol_df)):\n",
    "    chosen_protocol = protocol_df.index[protocol]\n",
    "    protocol_duration = protocol_df['duration'][protocol]\n",
    "    protocol_name = protocol_df['name'][protocol]\n",
    "    protocol_validity_i = Photodiode.average_image(ca_img_dm.dFoF0, visual_stim.order, chosen_protocol,protocol_duration, protocol_name, F_stim_init_indexes, ca_img_dm.fs, num_samples, save_dir, file_prefix=\"_\".join([unique_id, id_version]))\n",
    "    protocol_validity.append(protocol_validity_i)\n",
    "\n",
    "filename_protocol = \"_\".join([unique_id, id_version, 'protocol_validity']) + \".npz\"\n",
    "np.savez(os.path.join(save_dir, filename_protocol), **{key: value for d in protocol_validity for key, value in d.items()})\n",
    "print(protocol_validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spontaneous behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spont_stimuli_id, _ = spont.get_spont_stim(visual_stim)\n",
    "sigma = 5\n",
    "\n",
    "if len(spont_stimuli_id) > 0 :\n",
    "    spont_speed_corr_list = []\n",
    "    spont_facemotion_corr_list = []\n",
    "    spont_pupil_corr_list = []\n",
    "    valid_neurons_speed_list = []\n",
    "    valid_neurons_facemotion_list = []\n",
    "    valid_neurons_pupil_list = []\n",
    "    \n",
    "    idx_lim_protocol, spont_stimuli_id_order, F_spontaneous = visual_stim.get_protocol_onset_index(spont_stimuli_id, F_stim_init_indexes, ca_img_dm.fs, tseries=ca_img_dm.dFoF0)\n",
    "\n",
    "    spont_df = protocol_df.loc[spont_stimuli_id_order]\n",
    "\n",
    "    for i, id  in zip(range(len(spont_stimuli_id_order)), spont_stimuli_id_order):\n",
    "        [start_spont_index, end_spont_index] = idx_lim_protocol[i]\n",
    "        name_stimuli = spont_df.loc[spont_stimuli_id_order[i]]['name']\n",
    "        save_spont_dir = os.path.join(save_dir, \"_\".join([unique_id, 'spontaneous']))\n",
    "        save_spont_dir_i = os.path.join(save_spont_dir, name_stimuli)\n",
    "        if not os.path.exists(save_spont_dir_i) : os.makedirs(save_spont_dir_i)\n",
    "\n",
    "        time_stamps_spont = new_time_stamps[start_spont_index:end_spont_index]\n",
    "        print(f\"Spontaneous activity time {name_stimuli} {i}: from {time_stamps_spont[0]} s to {time_stamps_spont[-1]} s\")\n",
    "\n",
    "        # Speed correlation\n",
    "        speed_spont = speed[start_spont_index:end_spont_index]\n",
    "        spont_speed_corr, valid_neurons_temp = spont.compute_spont_corr(speed_spont, F_spontaneous[i], time_stamps_spont, sigma, 'speed', save_spont_dir_i)\n",
    "        spont_speed_corr_list.append(spont_speed_corr)\n",
    "        valid_neurons_speed_list.append(valid_neurons_temp)\n",
    "        spont.colormap_perm_test(time_stamps_spont, F_spontaneous[i], speed_spont, valid_neurons_temp, spont_speed_corr, sigma=sigma, label='speed', save_path=save_spont_dir_i)\n",
    "\n",
    "        if not face_cam_dm.no_face_data :\n",
    "            # Facemotion correlation\n",
    "            facemotion_spont = facemotion[start_spont_index:end_spont_index]\n",
    "            spont_facemotion_corr, valid_neurons_temp = spont.compute_spont_corr(facemotion_spont, F_spontaneous[i], time_stamps_spont, sigma, 'facemotion', save_spont_dir_i)\n",
    "            spont_facemotion_corr_list.append(spont_facemotion_corr)\n",
    "            valid_neurons_facemotion_list.append(valid_neurons_temp)\n",
    "            spont.colormap_perm_test(time_stamps_spont, F_spontaneous[i], facemotion_spont, valid_neurons_temp, spont_facemotion_corr, sigma=sigma, label='facemotion', save_path=save_spont_dir_i)\n",
    "\n",
    "            # Pupil correlation\n",
    "            pupil_spont = pupil[start_spont_index:end_spont_index]\n",
    "            if spont_df.loc[id].analyze_pupil :\n",
    "                spont_pupil_corr, valid_neurons_temp = spont.compute_spont_corr(pupil_spont, F_spontaneous[i], time_stamps_spont, sigma, 'pupil', save_spont_dir_i)\n",
    "                spont_pupil_corr_list.append(spont_pupil_corr)\n",
    "                valid_neurons_pupil_list.append(valid_neurons_temp)\n",
    "                spont.colormap_perm_test(time_stamps_spont, F_spontaneous[i], pupil_spont, valid_neurons_temp, spont_pupil_corr, sigma=sigma, label='pupil', save_path=save_spont_dir_i)\n",
    "\n",
    "    speed_corr = np.dot(np.array(spont_speed_corr_list).T, spont_df.duration/np.sum(spont_df.duration))\n",
    "    valid_neurons_speed = spont.get_valid_neurons(valid_neurons_speed_list)\n",
    "    spont.pie_plot(len(valid_neurons_speed), len(ca_img_dm._list_ROIs_idx) - len(valid_neurons_speed), save_spont_dir, 'speed')\n",
    "    valid_neurons_speed_list2 = np.zeros((len(ca_img_dm._list_ROIs_idx), len(valid_neurons_speed_list)))\n",
    "    for i in range(len(valid_neurons_speed_list)) : \n",
    "        valid_neurons_speed_list2[valid_neurons_speed_list[i], i] = 1\n",
    "\n",
    "    if not face_cam_dm.no_face_data :\n",
    "        facemotion_corr = np.dot(np.array(spont_facemotion_corr_list).T, spont_df.duration/np.sum(spont_df.duration))\n",
    "        valid_neurons_facemotion = spont.get_valid_neurons(valid_neurons_facemotion_list)\n",
    "        spont.pie_plot(len(valid_neurons_facemotion), len(ca_img_dm._list_ROIs_idx) - len(valid_neurons_facemotion), save_spont_dir, 'facemotion')\n",
    "        valid_neurons_facemotion_list2 = np.zeros((len(ca_img_dm._list_ROIs_idx), len(valid_neurons_facemotion_list)))\n",
    "        for i in range(len(valid_neurons_facemotion_list)) : \n",
    "            valid_neurons_facemotion_list2[valid_neurons_facemotion_list[i], i] = 1\n",
    "\n",
    "        if len(spont_pupil_corr_list) > 0 :\n",
    "            spont_dt_pupil = spont_df[spont_df.analyze_pupil == 1].duration\n",
    "            pupil_corr = np.dot(np.array(spont_pupil_corr_list).T, spont_dt_pupil/np.sum(spont_dt_pupil))\n",
    "            valid_neurons_pupil = spont.get_valid_neurons(valid_neurons_pupil_list)\n",
    "            spont.pie_plot(len(valid_neurons_pupil), len(ca_img_dm._list_ROIs_idx) - len(valid_neurons_pupil), save_spont_dir, 'pupil')\n",
    "            valid_neurons_pupil_list2 = np.zeros((len(ca_img_dm._list_ROIs_idx), len(valid_neurons_pupil_list)))\n",
    "            for i in range(len(valid_neurons_pupil_list)) : \n",
    "                valid_neurons_pupil_list2[valid_neurons_pupil_list[i], i] = 1\n",
    "        else :\n",
    "            nb_rois = len(ca_img_dm._list_ROIs_idx)\n",
    "            nan_array = np.empty(nb_rois)\n",
    "            nan_array.fill(np.nan)\n",
    "            pupil_corr = nan_array\n",
    "            valid_neurons_pupil_list2 = []\n",
    "    \n",
    "    else :\n",
    "        nb_rois = len(ca_img_dm._list_ROIs_idx)\n",
    "        nan_array = np.empty(nb_rois)\n",
    "        nan_array.fill(np.nan)\n",
    "        facemotion_corr, pupil_corr = nan_array, nan_array\n",
    "        valid_neurons_facemotion_list2, valid_neurons_pupil_list2 = [], []\n",
    "        \n",
    "else : \n",
    "    speed_corr, facemotion_corr, pupil_corr = np.array(speed_corr_list), np.array(facemotion_corr_list), np.array(pupil_corr_list)\n",
    "    valid_neurons_speed_list2, valid_neurons_facemotion_list2, valid_neurons_pupil_list2 = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set variables for saving and GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving file\n",
    "photodiode = (Psignal_time, Psignal)\n",
    "pupilAndTimeSt  = (new_time_stamps, pupil)\n",
    "fmotionAndTimeSt  = (new_time_stamps, facemotion)\n",
    "speedAndTimeSt = (new_time_stamps, speed)\n",
    "background_image_path = os.path.join(base_path, \"Mean_image_grayscale.png\")\n",
    "filename_protocol = \"_\".join([unique_id, id_version, 'protocol_validity_2']) + \".npz\"\n",
    "protocol_validity_npz = np.load(os.path.join(save_dir, filename_protocol), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save ouptut files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual stimuli info in excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"_\".join([unique_id, id_version, 'visual_stim_info']) + \".xlsx\"\n",
    "visual_stim.export_df_to_excel(save_dir, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"_\".join([unique_id, id_version, 'postprocessing']) + \".h5\"\n",
    "H5_dir = os.path.join(save_dir, filename)\n",
    "hf = h5py.File(H5_dir, 'w')\n",
    "behavioral_group = hf.create_group('Behavioral')\n",
    "correlation = behavioral_group.create_group(\"Correlation\")\n",
    "spont_correlation = behavioral_group.create_group(\"Spont_correlation\")\n",
    "caImg_group = hf.create_group('Ca_imaging')\n",
    "caImg_full_trace = caImg_group.create_group('full_trace')\n",
    "stimuli_group = hf.create_group(\"Stimuli\")\n",
    "rois_group = hf.create_group(\"ROIs\")\n",
    "states_group = hf.create_group(\"Arousal states\")\n",
    "if not face_cam_dm.no_face_data :\n",
    "    states_with_pupil = states_group.create_group(\"Arousal states pupil\")\n",
    "    frame_bounds_pupil = states_with_pupil.create_group(\"Frame bounds\")\n",
    "    time_bounds_pupil = states_with_pupil.create_group(\"Time bounds\")\n",
    "    states_with_facemotion = states_group.create_group(\"Arousal states facemotion\")\n",
    "    frame_bounds_facemotion = states_with_facemotion.create_group(\"Frame bounds\")\n",
    "    time_bounds_facemotion = states_with_facemotion.create_group(\"Time bounds\")\n",
    "else :\n",
    "    frame_bounds = states_group.create_group(\"Frame bounds\")\n",
    "    time_bounds = states_group.create_group(\"Time bounds\")\n",
    "\n",
    "file.create_H5_dataset(behavioral_group, [speedAndTimeSt, fmotionAndTimeSt, pupilAndTimeSt, photodiode], ['Speed', 'FaceMotion', 'Pupil', 'Photodiode'])\n",
    "file.create_H5_dataset(correlation, [speed_corr_list, facemotion_corr_list, pupil_corr_list], ['speed_corr', 'facemotion_corr', 'pupil_corr'])\n",
    "if len(spont_stimuli_id) > 0 :\n",
    "    file.create_H5_dataset(spont_correlation, [spont_speed_corr_list, spont_facemotion_corr_list, spont_pupil_corr_list], ['speed_corr', 'facemotion_corr', 'pupil_corr'])\n",
    "    spont_valid_rois = spont_correlation.create_group(\"Valid_ROIs\")\n",
    "    file.create_H5_dataset(spont_valid_rois, [valid_neurons_speed_list2, valid_neurons_facemotion_list2, valid_neurons_pupil_list2], ['speed', 'facemotion', 'pupil'])\n",
    "caImg_group.create_dataset('Time', data=ca_img_dm.time_stamps)\n",
    "file.create_H5_dataset(caImg_full_trace, [ca_img_dm.raw_F, ca_img_dm.raw_Fneu, ca_img_dm.fluorescence, ca_img_dm.f0, ca_img_dm.dFoF0], \n",
    "                                    ['raw_F', 'raw_Fneu', 'F', 'F0', 'dFoF0'])\n",
    "file.create_H5_dataset(stimuli_group, [visual_stim.real_time_onset, F_Time_start_realigned, F_stim_init_indexes], \n",
    "                                    ['time_onset', 'time_onset_caimg_timescale', 'idx_onset_caimg_timescale'])\n",
    "if cmi is not None :\n",
    "    file.create_H5_dataset(stimuli_group, [cmi, surround_sup_cross, surround_sup_iso], ['cmi', 'surround_sup_cross', 'surround_sup_iso'])\n",
    "file.create_H5_dataset(rois_group, [detected_roi, kept2p_ROI, kept_ROI_alpha, kept_ROI_F0], \n",
    "                                    ['0_original', '1_neuropil', '2_alpha', '3_F0'])\n",
    "if not face_cam_dm.no_face_data :\n",
    "    file.create_H5_dataset(frame_bounds_pupil, [states_window_pupil['run'], states_window_pupil['AS'], states_window_pupil['rest']], ['Run', 'AS', 'Rest'])\n",
    "    file.create_H5_dataset(time_bounds_pupil, [real_time_states_pupil['run'], real_time_states_pupil['AS'], real_time_states_pupil['rest']], ['Run', 'AS', 'Rest'])\n",
    "    file.create_H5_dataset(frame_bounds_facemotion, [states_window_facemotion['run'], states_window_facemotion['AS'], states_window_facemotion['rest']], ['Run', 'AS', 'Rest'])\n",
    "    file.create_H5_dataset(time_bounds_facemotion, [real_time_states_facemotion['run'], real_time_states_facemotion['AS'], real_time_states_facemotion['rest']], ['Run', 'AS', 'Rest'])\n",
    "else :\n",
    "    file.create_H5_dataset(frame_bounds, [states_window['run'], states_window['rest']], ['Run', 'Rest'])\n",
    "    file.create_H5_dataset(time_bounds, [real_time_states['run'], real_time_states['rest']], ['Run', 'Rest'])\n",
    "\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"_\".join([unique_id, id_version, 'trials'])\n",
    "trials.save_trials(save_dir, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcium imaging stat.npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"_\".join([unique_id, id_version, 'stat.npy'])\n",
    "np.save(os.path.join(save_dir, filename), ca_img_dm.stat, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPILE :\n",
    "    data_df = pd.DataFrame({\n",
    "                \"Session_id\": unique_id, \"Output_id\": id_version, \"Protocol\": global_protocol, \"Experimenter\": experimenter, \"Mouse_id\": subject_id_anibio,\n",
    "                'Mean_speed' : np.nanmean(speed), 'Std_speed' : np.nanstd(speed),\n",
    "                'Mean_fmotion' : np.nanmean(facemotion), 'Std_fmotion' : np.nanstd(facemotion),\n",
    "                'Mean_pupil' : np.nanmean(pupil), 'Std_pupil' : np.nanstd(pupil),\n",
    "                'Spontaneous' : True if len(spont_stimuli_id) > 0 else False,\n",
    "                'Mean_speed_corr' : np.nanmean(speed_corr), \n",
    "                'Mean_fmotion_corr' : np.nanmean(facemotion_corr),\n",
    "                'Mean_pupil_corr' : np.nanmean(pupil_corr), \n",
    "                'Mean_dFoF0' : np.nanmean(ca_img_dm.dFoF0), \n",
    "                'Run % (pupil)' : run_ratio_pupil if not face_cam_dm.no_face_data else None, \n",
    "                'AS % (pupil)' : as_ratio_pupil if not face_cam_dm.no_face_data else None,\n",
    "                'Rest % (pupil)' : rest_ratio_pupil if not face_cam_dm.no_face_data else None,\n",
    "                'Run % (motion)' : run_ratio_facemotion if not face_cam_dm.no_face_data else None, \n",
    "                'AS % (motion)' : as_ratio_facemotion if not face_cam_dm.no_face_data else None, \n",
    "                'Rest % (motion)' : rest_ratio_facemotion if not face_cam_dm.no_face_data else None,\n",
    "                'Run %' : run_ratio if face_cam_dm.no_face_data else None, \n",
    "                'Rest %' : rest_ratio if face_cam_dm.no_face_data else None, \n",
    "                }, index=[0]).set_index(\"Session_id\")\n",
    "    file.compile_xlsx_file(data_df, compile_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\"Date\" : datetime.date.today(),\n",
    "            \"Time\" : datetime.datetime.now().time(),\n",
    "            \"Session_id\" : unique_id,\n",
    "            \"Neuron type\" : neuron_type,\n",
    "            \"Neuropil impact factor\" : ca_img_dm._neuropil_if,\n",
    "            \"F0 calculateion method\" : F0_method,\n",
    "            \"2p starting delay\" : starting_delay_2p,\n",
    "            \"Bootstrapping nb of samples\" : num_samples,\n",
    "            \"Speed threshold\" : f\"{speed_threshold} (cm/s)\",\n",
    "            \"Facemotion threshold\" : f\"{facemotion_threshold} (std)\",\n",
    "            \"Pupil threshold\" :  f\"{pupil_threshold} ({pupil_threshold_type})\",\n",
    "            \"Minimum running window\" : min_run_window,\n",
    "            \"Minimum AS window\" : min_as_window,\n",
    "            \"Minimum rest window\" : min_rest_window,\n",
    "            \"Speed filter kernel\" : speed_filter_kernel,\n",
    "            \"Motion filter kernel\" : motion_filter_kernel,\n",
    "            \"Pupil filter kernel\" : pupil_filter_kernel,\n",
    "            \"Fluorescence filter kernel\" : dFoF_filter_kernel,\n",
    "            \"Analyzed folder\" : base_path,\n",
    "            \"Saving folder\" : save_dir,\n",
    "            \"Compile folder\" : compile_dir\n",
    "            }\n",
    "file.save_analysis_settings(settings, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch visualization GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = QtWidgets.QApplication(sys.argv)\n",
    "main_window = VisualizationGUI(save_dir, \n",
    "                               ca_img_dm.stat, ca_img_dm.ops, background_image_path,\n",
    "                               protocol_validity_npz, \n",
    "                               speed_corr, facemotion_corr, pupil_corr, \n",
    "                               computed_F_norm, ca_img_dm.time_stamps, speedAndTimeSt, fmotionAndTimeSt, pupilAndTimeSt, photodiode, stim_time_period, \n",
    "                               red_image_path)\n",
    "main_window.show()\n",
    "app.exec_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualpipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
